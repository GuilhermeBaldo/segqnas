{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 18:59:52.238042: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-10 18:59:52.238057: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/guilherme/git/segqnas/test_simple_train.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/guilherme/git/segqnas/test_simple_train.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msegmentation_models\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msm\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/guilherme/git/segqnas/test_simple_train.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/guilherme/git/segqnas/test_simple_train.ipynb#ch0000000?line=4'>5</a>\u001b[0m sm\u001b[39m.\u001b[39mset_framework(\u001b[39m'\u001b[39m\u001b[39mtf.keras\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/segmentation_models/__init__.py:98\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m _framework \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mSM_FRAMEWORK\u001b[39m\u001b[39m'\u001b[39m, _DEFAULT_KERAS_FRAMEWORK)\n\u001b[1;32m     97\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     set_framework(_framework)\n\u001b[1;32m     99\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     other \u001b[39m=\u001b[39m _TF_KERAS_FRAMEWORK_NAME \u001b[39mif\u001b[39;00m _framework \u001b[39m==\u001b[39m _KERAS_FRAMEWORK_NAME \u001b[39melse\u001b[39;00m _KERAS_FRAMEWORK_NAME\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/segmentation_models/__init__.py:67\u001b[0m, in \u001b[0;36mset_framework\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     64\u001b[0m name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39mlower()\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m _KERAS_FRAMEWORK_NAME:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mefficientnet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m  \u001b[39m# init custom objects\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39m==\u001b[39m _TF_KERAS_FRAMEWORK_NAME:\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/keras/__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/__init__.py:42\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[1;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m     44\u001b[0m \u001b[39m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/data/__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m AUTOTUNE\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/data/experimental/__init__.py:95\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m service\n\u001b[1;32m     96\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatching\u001b[39;00m \u001b[39mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[1;32m     97\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatching\u001b[39;00m \u001b[39mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/data/experimental/service/__init__.py:387\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mThis module contains:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 387\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m    388\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m from_dataset_id\n\u001b[1;32m    389\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m register_dataset\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m data_service_pb2\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m compression_ops\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_server_lib\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_utils\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/data/experimental/ops/compression_ops.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m structure\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[39mas\u001b[39;00m ged_ops\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompress\u001b[39m(element):\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m type_spec\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_array_ops\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mragged\u001b[39;00m \u001b[39mimport\u001b[39;00m ragged_tensor\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_logging \u001b[39mas\u001b[39;00m logging\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecation\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/ops/ragged/ragged_tensor.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m type_spec\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[0;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m check_ops\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m control_flow_ops\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_ragged_conversion_ops\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/ops/check_ops.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_util\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m control_flow_ops\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m math_ops\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py:2341\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2329\u001b[0m \u001b[39m# @TODO(b/133606651) Replace \"shape_invariants\" with \"loop_vars_signature\".\u001b[39;00m\n\u001b[1;32m   2330\u001b[0m \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[1;32m   2331\u001b[0m \u001b[39m@tf_export\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mwhile_loop\u001b[39;49m\u001b[39m\"\u001b[39;49m, v1\u001b[39m=\u001b[39;49m[])\n\u001b[1;32m   2332\u001b[0m \u001b[39m@deprecation\u001b[39;49m\u001b[39m.\u001b[39;49mdeprecated_arg_values(\n\u001b[1;32m   2333\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2334\u001b[0m     \u001b[39m\"\"\"back_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[39;49;00m\n\u001b[1;32m   2335\u001b[0m \u001b[39mInstead of:\u001b[39;49;00m\n\u001b[1;32m   2336\u001b[0m \u001b[39mresults = tf.while_loop(c, b, vars, back_prop=False)\u001b[39;49;00m\n\u001b[1;32m   2337\u001b[0m \u001b[39mUse:\u001b[39;49;00m\n\u001b[1;32m   2338\u001b[0m \u001b[39mresults = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\"\"\"\u001b[39;49;00m,\n\u001b[1;32m   2339\u001b[0m     warn_once\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2340\u001b[0m     back_prop\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m-> 2341\u001b[0m \u001b[39mdef\u001b[39;49;00m \u001b[39mwhile_loop_v2\u001b[39;49m(cond,\n\u001b[1;32m   2342\u001b[0m                   body,\n\u001b[1;32m   2343\u001b[0m                   loop_vars,\n\u001b[1;32m   2344\u001b[0m                   shape_invariants\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2345\u001b[0m                   parallel_iterations\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m   2346\u001b[0m                   back_prop\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2347\u001b[0m                   swap_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   2348\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2349\u001b[0m                   name\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m):\n\u001b[1;32m   2350\u001b[0m   \u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;49;00m\n\u001b[1;32m   2351\u001b[0m \n\u001b[1;32m   2352\u001b[0m \u001b[39m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2505\u001b[0m \n\u001b[1;32m   2506\u001b[0m \u001b[39m  \"\"\"\u001b[39;49;00m\n\u001b[1;32m   2507\u001b[0m   \u001b[39mreturn\u001b[39;49;00m while_loop(\n\u001b[1;32m   2508\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[1;32m   2509\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2516\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2517\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:631\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    623\u001b[0m           logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    624\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    625\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m    626\u001b[0m               _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[1;32m    627\u001b[0m               func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    628\u001b[0m               \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[1;32m    629\u001b[0m   \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 631\u001b[0m doc \u001b[39m=\u001b[39m _add_deprecated_arg_value_notice_to_docstring(\n\u001b[1;32m    632\u001b[0m     func\u001b[39m.\u001b[39;49m\u001b[39m__doc__\u001b[39;49m, date, instructions, deprecated_kwargs)\n\u001b[1;32m    633\u001b[0m \u001b[39mreturn\u001b[39;00m tf_decorator\u001b[39m.\u001b[39mmake_decorator(func, new_func, \u001b[39m'\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m'\u001b[39m, doc)\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:87\u001b[0m, in \u001b[0;36m_add_deprecated_arg_value_notice_to_docstring\u001b[0;34m(doc, date, instructions, deprecated_name_value_dict)\u001b[0m\n\u001b[1;32m     81\u001b[0m deprecation_string \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     82\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (key, value)\n\u001b[1;32m     83\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(deprecated_name_value_dict\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m     85\u001b[0m when \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date)\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m decorator_utils\u001b[39m.\u001b[39;49madd_notice_to_docstring(\n\u001b[1;32m     88\u001b[0m     doc,\n\u001b[1;32m     89\u001b[0m     instructions,\n\u001b[1;32m     90\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mDEPRECATED FUNCTION ARGUMENT VALUES\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     91\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39m(deprecated argument values)\u001b[39;49m\u001b[39m'\u001b[39;49m, [\n\u001b[1;32m     92\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mSOME ARGUMENT VALUES ARE DEPRECATED: `(\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m)`. \u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     93\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mThey will be removed \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m\n\u001b[1;32m     94\u001b[0m         (deprecation_string, when), \u001b[39m'\u001b[39;49m\u001b[39mInstructions for updating:\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     95\u001b[0m     ],\n\u001b[1;32m     96\u001b[0m     notice_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mDeprecated\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/util/decorator_utils.py:104\u001b[0m, in \u001b[0;36madd_notice_to_docstring\u001b[0;34m(doc, instructions, no_doc_str, suffix_str, notice, notice_type)\u001b[0m\n\u001b[1;32m    102\u001b[0m   lines \u001b[39m=\u001b[39m [no_doc_str]\n\u001b[1;32m    103\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m   lines \u001b[39m=\u001b[39m _normalize_docstring(doc)\u001b[39m.\u001b[39msplitlines()\n\u001b[1;32m    105\u001b[0m   lines[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m suffix_str\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m notice:\n",
      "File \u001b[0;32m~/git/segqnas/.venv/lib/python3.8/site-packages/tensorflow/python/util/decorator_utils.py:57\u001b[0m, in \u001b[0;36m_normalize_docstring\u001b[0;34m(docstring)\u001b[0m\n\u001b[1;32m     55\u001b[0m   stripped \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mlstrip()\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m stripped:\n\u001b[0;32m---> 57\u001b[0m     indent \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(indent, \u001b[39mlen\u001b[39m(line) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39;49m(stripped))\n\u001b[1;32m     58\u001b[0m \u001b[39m# Remove indentation (first line is special):\u001b[39;00m\n\u001b[1;32m     59\u001b[0m trimmed \u001b[39m=\u001b[39m [lines[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstrip()]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sm.set_framework('tf.keras')\n",
    "\n",
    "from cnn.input import PascalVOC2012Dataset, Dataloader, get_training_augmentation, get_preprocessing\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_descriptor_filepath = os.path.join(\n",
    "    'pascalvoc12',\n",
    "    'VOCdevkit',\n",
    "    'VOC2012',\n",
    "    'ImageSets',\n",
    "    'Segmentation',\n",
    "    'train.txt',\n",
    ")\n",
    "\n",
    "val_dataset_descriptor_filepath = os.path.join(\n",
    "    'pascalvoc12',\n",
    "    'VOCdevkit',\n",
    "    'VOC2012',\n",
    "    'ImageSets',\n",
    "    'Segmentation',\n",
    "    'val.txt',\n",
    ")\n",
    "\n",
    "images_path = os.path.join(\n",
    "    'pascalvoc12', \n",
    "    'VOCdevkit', \n",
    "    'VOC2012', \n",
    "    'JPEGImages'\n",
    ")\n",
    "\n",
    "masks_path = os.path.join(\n",
    "    'pascalvoc12', \n",
    "    'VOCdevkit', \n",
    "    'VOC2012', \n",
    "    'SegmentationClass'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 224\n",
    "image_width = 224\n",
    "backbone = 'efficientnetb0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/git/segqnas/.venv/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:2029: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  warnings.warn('Using lambda is incompatible with multiprocessing. '\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PascalVOC2012Dataset(\n",
    "    train_dataset_descriptor_filepath,\n",
    "    images_path=images_path,\n",
    "    masks_path=masks_path,\n",
    "    image_height=image_height,\n",
    "    image_width=image_width,\n",
    "    #augmentation=get_training_augmentation(image_height, image_width),\n",
    "    preprocessing=get_preprocessing(sm.get_preprocessing(backbone))\n",
    ")\n",
    "\n",
    "val_dataset = PascalVOC2012Dataset(\n",
    "    val_dataset_descriptor_filepath,\n",
    "    images_path=images_path,\n",
    "    masks_path=masks_path,\n",
    "    image_height=image_height,\n",
    "    image_width=image_width,\n",
    "    preprocessing=get_preprocessing(sm.get_preprocessing(backbone))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = Dataloader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = Dataloader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 18:45:08.319961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-10 18:45:08.320141: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-10 18:45:08.320786: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-10 18:45:08.321024: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-10 18:45:08.321069: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-10 18:45:08.321109: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-10 18:45:08.321151: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-10 18:45:08.321191: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-10 18:45:08.321233: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-10 18:45:08.321239: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-10 18:45:08.321848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "net = sm.FPN(backbone, classes=21, input_shape=(image_height, image_width, 3), activation='softmax', encoder_weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
    "    optimizer='Adam',\n",
    "    loss=sm.losses.categorical_focal_dice_loss,\n",
    "    metrics=[sm.metrics.IOUScore(threshold=0.5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "history = net.fit(train_dataloader, \n",
    "                validation_data=val_dataloader,\n",
    "                epochs=50,\n",
    "                callbacks=[\n",
    "                    tf.keras.callbacks.EarlyStopping(\n",
    "                        monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5\n",
    "                    )\n",
    "                ],\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15b591e0ce635b5b9c208f30fdc7e069506189097a1aa8b055086f0ec8562519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
