{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python prepare_data_spleen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 00:20:47.948821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-20 00:20:48.041685: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-20 00:20:48.041698: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-20 00:20:48.582221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-20 00:20:48.582263: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-20 00:20:48.582268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-20 00:20:49.953829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 00:20:49.954236: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/Downloads/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-20 00:20:49.954288: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/Downloads/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-20 00:20:49.954328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/Downloads/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-20 00:20:49.954366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/Downloads/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-20 00:20:49.954401: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/Downloads/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-20 00:20:49.954444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/Downloads/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-20 00:20:49.954482: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/Downloads/git/segqnas/.venv/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-11-20 00:20:49.955339: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from cnn.model import build_net\n",
    "from spleen_dataset.dataloader import SpleenDataloader, SpleenDataset, get_training_augmentation, get_validation_augmentation\n",
    "from spleen_dataset.config import dataset_folder\n",
    "from spleen_dataset.utils import get_split_deterministic, get_list_of_patients\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   try:\n",
    "#     tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "#   except RuntimeError as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/Downloads/git/segqnas/.venv/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1149: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/Task09_Spleen_2D'\n",
    "\n",
    "patch_size = (128, 128)\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "skip_slices = 1\n",
    "stem_filters = 16\n",
    "max_depth = 4\n",
    "\n",
    "augmentation = get_training_augmentation(patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './spleen_dataset/data/Task09_Spleen/imagesTr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m patients \u001b[39m=\u001b[39m get_list_of_patients(dataset_folder)\n\u001b[1;32m      2\u001b[0m train_augmentation \u001b[39m=\u001b[39m get_training_augmentation(patch_size)\n\u001b[1;32m      3\u001b[0m val_augmentation \u001b[39m=\u001b[39m get_validation_augmentation(patch_size)\n",
      "File \u001b[0;32m~/Downloads/git/segqnas/spleen_dataset/utils.py:10\u001b[0m, in \u001b[0;36mget_list_of_patients\u001b[0;34m(base_dir)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_list_of_patients\u001b[39m(base_dir):\n\u001b[1;32m      9\u001b[0m     ct_directory \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_dir, \u001b[39m\"\u001b[39m\u001b[39mimagesTr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     ct_files \u001b[39m=\u001b[39m subfiles(ct_directory, prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mspleen\u001b[39;49m\u001b[39m\"\u001b[39;49m, join\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     11\u001b[0m     patients \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(get_patient_from_filename, ct_files))\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m patients\n",
      "File \u001b[0;32m~/Downloads/git/segqnas/spleen_dataset/utils.py:26\u001b[0m, in \u001b[0;36msubfiles\u001b[0;34m(folder, join, prefix, suffix, sort)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     l \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x, y: y\n\u001b[1;32m     24\u001b[0m res \u001b[39m=\u001b[39m [\n\u001b[1;32m     25\u001b[0m     l(folder, i)\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(folder)\n\u001b[1;32m     27\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder, i))\n\u001b[1;32m     28\u001b[0m     \u001b[39mand\u001b[39;00m (prefix \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m i\u001b[39m.\u001b[39mstartswith(prefix))\n\u001b[1;32m     29\u001b[0m     \u001b[39mand\u001b[39;00m (suffix \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m i\u001b[39m.\u001b[39mendswith(suffix))\n\u001b[1;32m     30\u001b[0m ]\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m sort:\n\u001b[1;32m     32\u001b[0m     res\u001b[39m.\u001b[39msort()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './spleen_dataset/data/Task09_Spleen/imagesTr'"
     ]
    }
   ],
   "source": [
    "patients = get_list_of_patients(dataset_folder)\n",
    "train_augmentation = get_training_augmentation(patch_size)\n",
    "val_augmentation = get_validation_augmentation(patch_size)\n",
    "\n",
    "train_patients, val_patients = get_split_deterministic(patients, fold=1, num_splits=5, random_state=0)\n",
    "\n",
    "train_dataset = SpleenDataset(train_patients, only_non_empty_slices=True, skip_slices=skip_slices)\n",
    "val_dataset = SpleenDataset(val_patients, only_non_empty_slices=True)\n",
    "\n",
    "train_dataloader = SpleenDataloader(train_dataset, batch_size, train_augmentation)\n",
    "val_dataloader = SpleenDataloader(val_dataset, batch_size, val_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = random.randint(0, len(train_dataset))\n",
    "image, label = train_dataset[id]\n",
    "\n",
    "print(image.shape)\n",
    "print(label.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(image)\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = random.randint(0, len(train_dataloader))\n",
    "images, labels = train_dataloader[id]\n",
    "\n",
    "image = images[0]\n",
    "label =labels[0]\n",
    "\n",
    "print(image.shape)\n",
    "print(label.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.imshow(image)\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax2.imshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_list = [\n",
    "    'down_vgg_3', \n",
    "    'down_vgg_3',\n",
    "    'down_vgg_3',\n",
    "    'down_vgg_3',\n",
    "    'non_vgg_3',\n",
    "    'up_vgg_3',\n",
    "    'up_vgg_3',\n",
    "    'up_vgg_3',\n",
    "    'up_vgg_3'\n",
    "]\n",
    "\n",
    "fn_dict = {\n",
    "    'down_vgg_3': {'cell': 'DownscalingCell', 'block': 'VGGBlock', 'kernel': 3, 'prob': 1/3},\n",
    "    'up_vgg_3':   {'cell': 'UpscalingCell',   'block': 'VGGBlock', 'kernel': 3, 'prob': 1/3},\n",
    "    'non_vgg_3':  {'cell': 'NonscalingCell',  'block': 'VGGBlock', 'kernel': 3, 'prob': 1/3},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_net((*patch_size, 1), stem_filters, max_depth, num_classes, fn_dict, net_list)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "plot_model(model,\n",
    "           to_file='model.png',\n",
    "           show_shapes=True,\n",
    "           show_layer_names=True,\n",
    "           rankdir='TB'\n",
    "            )\n",
    "Image('model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\", mode=\"min\", verbose=1, patience=5\n",
    "        ),\n",
    "        # ModelCheckpoint(\n",
    "        #     \"best_model.h5\",\n",
    "        #     save_best_only=True,\n",
    "        #     monitor=\"val_loss\",\n",
    "        #     mode=\"min\",\n",
    "        # ),\n",
    "        # TensorBoard(log_dir=\"./logs\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the dice coeff results (accuracy) as a function of the number of epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['gen_dice_coef'])\n",
    "plt.plot(history.history['val_gen_dice_coef'])\n",
    "plt.title('Model: Generalized Dice Coeficient')\n",
    "plt.ylabel('Dice Coef')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# plotting the dice coeff results (loss function) as a function of the number of epochs\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model: Generalized Dice Coeficient')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir='./logs'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "088339a8e2ec17b5c81ee3936f19d43f363773a72f3cd0df1950fc6c797a05d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
