{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 01:36:16.757573: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from cnn import model\n",
    "\n",
    "from cnn.input import (\n",
    "    get_list_of_patients,\n",
    "    get_training_augmentation,\n",
    "    get_validation_augmentation,\n",
    "    Dataset,\n",
    "    Dataloader,\n",
    "    get_split_deterministic,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    \"data_path\": \"spleen_dataset/data/Task09_Spleen_preprocessed\",\n",
    "    \"num_classes\": 2,\n",
    "    \"num_channels\": 1,\n",
    "    \"skip_slices\": 0,\n",
    "    \"image_size\": 128,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"eval_epochs\": 10,\n",
    "    \"folds\": 5,\n",
    "    \"initializations\": 5,\n",
    "    \"stem_filters\": 16,\n",
    "    \"max_depth\": 4\n",
    "}\n",
    "\n",
    "unet_net_list = [\n",
    "    \"vgg_n_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_n_3\" \n",
    "]\n",
    "\n",
    "experiment_1_spleen_net_list = [\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_n_3\",\n",
    "    \"ide_d\",\n",
    "    \"vgg_n_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"ide_d\",\n",
    "    \"vgg_n_3\",\n",
    "    \"ide_d\"\n",
    "]\n",
    "\n",
    "experiment_2_spleen_net_list = [\n",
    "    \"inc_7\",\n",
    "    \"vgg_5\",\n",
    "    \"vgg_5\",\n",
    "    \"res_5\",\n",
    "    \"den_7\",\n",
    "    \"vgg_7\",\n",
    "    \"den_5\",\n",
    "    \"res_5\",\n",
    "    \"inc_7\",\n",
    "    \"inc_5\",\n",
    "]\n",
    "\n",
    "experiment_2_spleen_cell_list = [\n",
    "    \"NonscalingCell\",\n",
    "    \"DownscalingCell\",\n",
    "    \"DownscalingCell\",\n",
    "    \"DownscalingCell\",\n",
    "    \"DownscalingCell\",\n",
    "    \"UpscalingCell\",\n",
    "    \"UpscalingCell\",\n",
    "    \"UpscalingCell\",\n",
    "    \"UpscalingCell\",\n",
    "    \"NonscalingCell\"\n",
    "]\n",
    "\n",
    "layer_dict = {\n",
    "    \"den_3\":   {                           \"block\": \"DenseBlock\",     \"kernel\": 3},\n",
    "    \"den_5\":   {                           \"block\": \"DenseBlock\",     \"kernel\": 5},\n",
    "    \"den_7\":   {                           \"block\": \"DenseBlock\",     \"kernel\": 7},\n",
    "    \"den_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\",     \"kernel\": 3},\n",
    "    \"den_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\",     \"kernel\": 5},\n",
    "    \"den_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\",     \"kernel\": 7},\n",
    "    \"den_n_3\": {\"cell\": \"NonscalingCell\",  \"block\": \"DenseBlock\",     \"kernel\": 3},\n",
    "    \"den_n_5\": {\"cell\": \"NonscalingCell\",  \"block\": \"DenseBlock\",     \"kernel\": 5},\n",
    "    \"den_n_7\": {\"cell\": \"NonscalingCell\",  \"block\": \"DenseBlock\",     \"kernel\": 7},\n",
    "    \"den_u_3\": {\"cell\": \"UpscalingCell\",   \"block\": \"DenseBlock\",     \"kernel\": 3},\n",
    "    \"den_u_5\": {\"cell\": \"UpscalingCell\",   \"block\": \"DenseBlock\",     \"kernel\": 5},\n",
    "    \"den_u_7\": {\"cell\": \"UpscalingCell\",   \"block\": \"DenseBlock\",     \"kernel\": 7},\n",
    "    \"inc_3\":   {                           \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_5\":   {                           \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_7\":   {                           \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_n_3\": {\"cell\": \"NonscalingCell\",  \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_n_5\": {\"cell\": \"NonscalingCell\",  \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_n_7\": {\"cell\": \"NonscalingCell\",  \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_u_3\": {\"cell\": \"UpscalingCell\",   \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_u_5\": {\"cell\": \"UpscalingCell\",   \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_u_7\": {\"cell\": \"UpscalingCell\",   \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"ide\":     {                           \"block\": \"IdentityBlock\"              },\n",
    "    \"ide_d\":   {\"cell\": \"DownscalingCell\", \"block\": \"IdentityBlock\"              },\n",
    "    \"ide_n\":   {\"cell\": \"NonscalingCell\",  \"block\": \"IdentityBlock\"              },\n",
    "    \"ide_u\":   {\"cell\": \"UpscalingCell\",   \"block\": \"IdentityBlock\"              },\n",
    "    \"res_3\":   {                           \"block\": \"ResNetBlock\",    \"kernel\": 3},\n",
    "    \"res_5\":   {                           \"block\": \"ResNetBlock\",    \"kernel\": 5},\n",
    "    \"res_7\":   {                           \"block\": \"ResNetBlock\",    \"kernel\": 7},\n",
    "    \"res_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\",    \"kernel\": 3},\n",
    "    \"res_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\",    \"kernel\": 5},\n",
    "    \"res_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\",    \"kernel\": 7},\n",
    "    \"res_n_3\": {\"cell\": \"NonscalingCell\",  \"block\": \"ResNetBlock\",    \"kernel\": 3},\n",
    "    \"res_n_5\": {\"cell\": \"NonscalingCell\",  \"block\": \"ResNetBlock\",    \"kernel\": 5},\n",
    "    \"res_n_7\": {\"cell\": \"NonscalingCell\",  \"block\": \"ResNetBlock\",    \"kernel\": 7},\n",
    "    \"res_u_3\": {\"cell\": \"UpscalingCell\",   \"block\": \"ResNetBlock\",    \"kernel\": 3},\n",
    "    \"res_u_5\": {\"cell\": \"UpscalingCell\",   \"block\": \"ResNetBlock\",    \"kernel\": 5},\n",
    "    \"res_u_7\": {\"cell\": \"UpscalingCell\",   \"block\": \"ResNetBlock\",    \"kernel\": 7},\n",
    "    \"vgg_3\":   {                           \"block\": \"VGGBlock\",       \"kernel\": 3},\n",
    "    \"vgg_5\":   {                           \"block\": \"VGGBlock\",       \"kernel\": 5},\n",
    "    \"vgg_7\":   {                           \"block\": \"VGGBlock\",       \"kernel\": 7},\n",
    "    \"vgg_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\",       \"kernel\": 3},\n",
    "    \"vgg_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\",       \"kernel\": 5},\n",
    "    \"vgg_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\",       \"kernel\": 7},\n",
    "    \"vgg_n_3\": {\"cell\": \"NonscalingCell\",  \"block\": \"VGGBlock\",       \"kernel\": 3},\n",
    "    \"vgg_n_5\": {\"cell\": \"NonscalingCell\",  \"block\": \"VGGBlock\",       \"kernel\": 5},\n",
    "    \"vgg_n_7\": {\"cell\": \"NonscalingCell\",  \"block\": \"VGGBlock\",       \"kernel\": 7},\n",
    "    \"vgg_u_3\": {\"cell\": \"UpscalingCell\",   \"block\": \"VGGBlock\",       \"kernel\": 3},\n",
    "    \"vgg_u_5\": {\"cell\": \"UpscalingCell\",   \"block\": \"VGGBlock\",       \"kernel\": 5},\n",
    "    \"vgg_u_7\": {\"cell\": \"UpscalingCell\",   \"block\": \"VGGBlock\",       \"kernel\": 7},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_train(train_params, layer_dict, net_list, cell_list=None):\n",
    "\n",
    "    data_path = train_params[\"data_path\"]\n",
    "    num_classes = train_params[\"num_classes\"]\n",
    "    num_channels = train_params[\"num_channels\"]\n",
    "    skip_slices = train_params[\"skip_slices\"]\n",
    "    image_size = train_params[\"image_size\"]\n",
    "    batch_size = train_params[\"batch_size\"]\n",
    "    epochs = train_params[\"epochs\"]\n",
    "    eval_epochs = train_params[\"eval_epochs\"]\n",
    "    num_folds = train_params[\"folds\"]\n",
    "    num_initializations = train_params[\"initializations\"]\n",
    "    stem_filters = train_params[\"stem_filters\"]\n",
    "    max_depth = train_params[\"max_depth\"]\n",
    "\n",
    "    patch_size = (image_size, image_size, num_channels)\n",
    "\n",
    "    patients = get_list_of_patients(data_path)\n",
    "    train_augmentation = get_training_augmentation(patch_size)\n",
    "    val_augmentation = get_validation_augmentation(patch_size)\n",
    "\n",
    "    val_gen_dice_coef_list = []\n",
    "\n",
    "    for initialization in range(num_initializations):\n",
    "        for fold in range(num_folds):\n",
    "\n",
    "            net = model.build_net(\n",
    "                input_shape=patch_size,\n",
    "                num_classes=num_classes,\n",
    "                stem_filters=stem_filters,\n",
    "                max_depth=max_depth,\n",
    "                layer_dict=layer_dict,\n",
    "                net_list=net_list,\n",
    "                cell_list=cell_list,\n",
    "            )\n",
    "\n",
    "            train_patients, val_patients = get_split_deterministic(\n",
    "                patients,\n",
    "                fold=fold,\n",
    "                num_splits=num_folds,\n",
    "                random_state=initialization,\n",
    "            )\n",
    "\n",
    "            train_dataset = Dataset(\n",
    "                data_path=data_path,\n",
    "                patients=train_patients,\n",
    "                only_non_empty_slices=True,\n",
    "            )\n",
    "\n",
    "            val_dataset = Dataset(\n",
    "                data_path=data_path,\n",
    "                patients=val_patients,\n",
    "                only_non_empty_slices=True,\n",
    "            )\n",
    "\n",
    "            train_dataloader = Dataloader(\n",
    "                dataset=train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                skip_slices=skip_slices,\n",
    "                augmentation=train_augmentation,\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            val_dataloader = Dataloader(\n",
    "                dataset=val_dataset,\n",
    "                batch_size=batch_size,\n",
    "                skip_slices=0,\n",
    "                augmentation=val_augmentation,\n",
    "                shuffle=False,\n",
    "            )\n",
    "\n",
    "            def learning_rate_fn(epoch):\n",
    "                initial_learning_rate = 1e-3\n",
    "                end_learning_rate = 1e-4\n",
    "                power = 0.9\n",
    "                return (\n",
    "                    (initial_learning_rate - end_learning_rate)\n",
    "                    * (1 - epoch / float(epochs)) ** (power)\n",
    "                ) + end_learning_rate\n",
    "\n",
    "            lr_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "                learning_rate_fn, verbose=False\n",
    "            )\n",
    "\n",
    "            history = net.fit(\n",
    "                train_dataloader,\n",
    "                validation_data=val_dataloader,\n",
    "                epochs=epochs,\n",
    "                verbose=0,\n",
    "                callbacks=[lr_callback],\n",
    "            )\n",
    "\n",
    "            history_eval_epochs = history.history[\"val_gen_dice_coef\"][-eval_epochs:]\n",
    "\n",
    "            val_gen_dice_coef_list.extend(history_eval_epochs)\n",
    "\n",
    "            mean_dsc = np.mean(val_gen_dice_coef_list)\n",
    "            std_dsc = np.std(val_gen_dice_coef_list)\n",
    "            print(\n",
    "                f\"{fold + initialization*num_folds}/{num_folds*num_initializations}: {mean_dsc} +- {std_dsc}\"\n",
    "            )\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(history.history[\"gen_dice_coef\"])\n",
    "            plt.plot(history.history[\"val_gen_dice_coef\"])\n",
    "            plt.title(\"DSC\")\n",
    "            plt.ylabel(\"DSC\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "            plt.show()\n",
    "\n",
    "    mean_dsc = np.mean(val_gen_dice_coef_list)\n",
    "    std_dsc = np.std(val_gen_dice_coef_list)\n",
    "\n",
    "    return mean_dsc, std_dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/miniconda3/envs/qnas/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:1149: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "2022-12-01 01:36:18.901278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 01:36:20.687391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22122 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:3b:00.0, compute capability: 8.0\n",
      "2022-12-01 01:36:20.689215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22122 MB memory:  -> device: 1, name: NVIDIA A30, pci bus id: 0000:af:00.0, compute capability: 8.0\n",
      "2022-12-01 01:36:20.690861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22122 MB memory:  -> device: 2, name: NVIDIA A30, pci bus id: 0000:d8:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "cross_val_train(train_params=train_params, layer_dict=layer_dict, net_list=unet_net_list, cell_list=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_train(train_params=train_params, layer_dict=layer_dict, net_list=experiment_1_spleen_net_list, cell_list=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_train(train_params=train_params, layer_dict=layer_dict, net_list=experiment_2_spleen_net_list, cell_list=experiment_2_spleen_cell_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('qnas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8820744234b703bd445442e6ebc9db61d869d1d6be3e6a35ae5b30db245b9f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
