{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn.model import build_net\n",
    "\n",
    "from cnn.input import Dataloader, Dataset, get_training_augmentation, get_validation_augmentation, get_list_of_patients, get_split_deterministic\n",
    "\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    TensorBoard,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], False)\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"spleen_dataset/data/Task09_Spleen_preprocessed\"\n",
    "#data_path = \"prostate_dataset/data/Task05_Prostate_preprocessed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = get_list_of_patients(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (128, 128, 1)\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "train_augmentation = get_training_augmentation(patch_size)\n",
    "val_augmentation = get_validation_augmentation(patch_size)\n",
    "\n",
    "net_list = [\n",
    "    \"vgg_n_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_n_3\",\n",
    "]\n",
    "\n",
    "fn_dict = {\n",
    "    \"den_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 3},\n",
    "    \"den_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 5},\n",
    "    \"den_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 7},\n",
    "    \"den_n_3\": {\"cell\": \"NonscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 3},\n",
    "    \"den_n_5\": {\"cell\": \"NonscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 5},\n",
    "    \"den_n_7\": {\"cell\": \"NonscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 7},\n",
    "    \"den_u_3\": {\"cell\": \"UpscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 3},\n",
    "    \"den_u_5\": {\"cell\": \"UpscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 5},\n",
    "    \"den_u_7\": {\"cell\": \"UpscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 7},\n",
    "    \"inc_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_n_3\": {\"cell\": \"NonscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_n_5\": {\"cell\": \"NonscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_n_7\": {\"cell\": \"NonscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_u_3\": {\"cell\": \"UpscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_u_5\": {\"cell\": \"UpscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_u_7\": {\"cell\": \"UpscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"ide_d\": {\n",
    "        \"cell\": \"DownscalingCell\",\n",
    "        \"block\": \"IdentityBlock\",\n",
    "    },\n",
    "    \"ide_n\": {\n",
    "        \"cell\": \"NonscalingCell\",\n",
    "        \"block\": \"IdentityBlock\",\n",
    "    },\n",
    "    \"ide_u\": {\n",
    "        \"cell\": \"UpscalingCell\",\n",
    "        \"block\": \"IdentityBlock\",\n",
    "    },\n",
    "    \"res_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 3},\n",
    "    \"res_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 5},\n",
    "    \"res_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 7},\n",
    "    \"res_n_3\": {\"cell\": \"NonscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 3},\n",
    "    \"res_n_5\": {\"cell\": \"NonscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 5},\n",
    "    \"res_n_7\": {\"cell\": \"NonscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 7},\n",
    "    \"res_u_3\": {\"cell\": \"UpscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 3},\n",
    "    \"res_u_5\": {\"cell\": \"UpscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 5},\n",
    "    \"res_u_7\": {\"cell\": \"UpscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 7},\n",
    "    \"vgg_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 3},\n",
    "    \"vgg_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 5},\n",
    "    \"vgg_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 7},\n",
    "    \"vgg_n_3\": {\"cell\": \"NonscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 3},\n",
    "    \"vgg_n_5\": {\"cell\": \"NonscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 5},\n",
    "    \"vgg_n_7\": {\"cell\": \"NonscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 7},\n",
    "    \"vgg_u_3\": {\"cell\": \"UpscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 3},\n",
    "    \"vgg_u_5\": {\"cell\": \"UpscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 5},\n",
    "    \"vgg_u_7\": {\"cell\": \"UpscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 7},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen_dice_coef_list = []\n",
    "num_splits = 5\n",
    "num_initializations = 1\n",
    "epochs = 30\n",
    "max_depth = 4\n",
    "stem_filters = 16\n",
    "evaluation_epochs = 6\n",
    "\n",
    "for initialization in range(num_initializations):\n",
    "\n",
    "    for fold in range(num_splits):\n",
    "        train_patients, val_patients = get_split_deterministic(\n",
    "            patients, fold=fold, num_splits=num_splits, random_state=initialization\n",
    "        )\n",
    "\n",
    "        train_dataset = Dataset(\n",
    "            data_path=data_path, \n",
    "            patients=train_patients, \n",
    "            only_non_empty_slices=True\n",
    "        )\n",
    "        \n",
    "        val_dataset = Dataset(\n",
    "            data_path=data_path, \n",
    "            patients=val_patients,\n",
    "            only_non_empty_slices=True\n",
    "        )\n",
    "\n",
    "        train_dataloader = Dataloader(\n",
    "            dataset=train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            skip_slices=1,\n",
    "            augmentation=train_augmentation\n",
    "        )\n",
    "\n",
    "        val_dataloader = Dataloader(\n",
    "            dataset=val_dataset, \n",
    "            batch_size=batch_size, \n",
    "            augmentation=val_augmentation\n",
    "        )\n",
    "\n",
    "        model = build_net(\n",
    "            patch_size, \n",
    "            stem_filters, \n",
    "            max_depth, \n",
    "            num_classes, \n",
    "            fn_dict, \n",
    "            net_list\n",
    "        )\n",
    "\n",
    "        def learning_rate_fn(epoch):\n",
    "            initial_learning_rate = 1e-3\n",
    "            end_learning_rate = 1e-4\n",
    "            power = 0.9\n",
    "            return (\n",
    "                (initial_learning_rate - end_learning_rate)\n",
    "                * (1 - epoch / float(epochs)) ** (power)\n",
    "            ) + end_learning_rate\n",
    "\n",
    "        lr_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "            learning_rate_fn, verbose=False\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_dataloader,\n",
    "            validation_data=val_dataloader,\n",
    "            epochs=epochs,\n",
    "            verbose=0,\n",
    "            callbacks=[lr_callback],\n",
    "        )\n",
    "\n",
    "        print(history.history[\"val_gen_dice_coef\"][-evaluation_epochs:])\n",
    "\n",
    "        val_gen_dice_coef_list.extend(\n",
    "            history.history[\"val_gen_dice_coef\"][-evaluation_epochs:]\n",
    "        )\n",
    "\n",
    "        # for patient in val_patients:\n",
    "        #     patient_dataset = ProstateDataset([patient], only_non_empty_slices=True)\n",
    "        #     patient_dataloader = ProstateDataloader(patient_dataset, 1, val_augmentation, shuffle=False)\n",
    "        #     results = model.evaluate(patient_dataloader)\n",
    "        #     val_gen_dice_coef_patient = results[-1]\n",
    "        #     val_gen_dice_coef_list.append(val_gen_dice_coef_patient)\n",
    "\n",
    "        # plotting the dice coef results (accuracy) as a function of the number of epochs\n",
    "        plt.figure()\n",
    "        plt.plot(history.history[\"gen_dice_coef\"])\n",
    "        plt.plot(history.history[\"val_gen_dice_coef\"])\n",
    "        plt.title(\"DSC\")\n",
    "        plt.ylabel(\"DSC\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "\n",
    "        # plotting the dice coef results (loss function) as a function of the number of epochs\n",
    "        # plt.figure()\n",
    "        # plt.plot(history.history['loss'])\n",
    "        # plt.plot(history.history['val_loss'])\n",
    "        # plt.title('Model: Generalized Dice Coeficient')\n",
    "        # plt.ylabel('Dice Loss')\n",
    "        # plt.xlabel('Epoch')\n",
    "        # plt.legend(['Train', 'Test'], loc='upper right')\n",
    "        # plt.show()\n",
    "\n",
    "mean_val_gen_dice_coef = np.mean(val_gen_dice_coef_list)\n",
    "std_val_gen_dice_coef = np.std(val_gen_dice_coef_list)\n",
    "\n",
    "print(f\"Dice {mean_val_gen_dice_coef} +- {std_val_gen_dice_coef}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79f34ae2563cf6a2df54fcc2fc47cdbaf206a86844b28bd2ca11c1c53b338106"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
