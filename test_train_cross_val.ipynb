{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn.model import build_net\n",
    "\n",
    "from prostate_dataset.dataloader import (\n",
    "    ProstateDataloader,\n",
    "    ProstateDataset,\n",
    "    get_training_augmentation,\n",
    "    get_validation_augmentation,\n",
    ")\n",
    "from prostate_dataset.config import dataset_folder\n",
    "from prostate_dataset.utils import get_split_deterministic, get_list_of_patients\n",
    "\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    TensorBoard,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], False)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = get_list_of_patients(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (128, 128, 2)\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "train_augmentation = get_training_augmentation(patch_size)\n",
    "val_augmentation = get_validation_augmentation(patch_size)\n",
    "\n",
    "net_list = [\n",
    "    \"vgg_n_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_d_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_u_3\",\n",
    "    \"vgg_n_3\",\n",
    "]\n",
    "\n",
    "fn_dict = {\n",
    "    \"den_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 3},\n",
    "    \"den_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 5},\n",
    "    \"den_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 7},\n",
    "    \"den_n_3\": {\"cell\": \"NonscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 3},\n",
    "    \"den_n_5\": {\"cell\": \"NonscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 5},\n",
    "    \"den_n_7\": {\"cell\": \"NonscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 7},\n",
    "    \"den_u_3\": {\"cell\": \"UpscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 3},\n",
    "    \"den_u_5\": {\"cell\": \"UpscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 5},\n",
    "    \"den_u_7\": {\"cell\": \"UpscalingCell\", \"block\": \"DenseBlock\", \"kernel\": 7},\n",
    "    \"inc_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_n_3\": {\"cell\": \"NonscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_n_5\": {\"cell\": \"NonscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_n_7\": {\"cell\": \"NonscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_u_3\": {\"cell\": \"UpscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_u_5\": {\"cell\": \"UpscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_u_7\": {\"cell\": \"UpscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"ide_d\": {\n",
    "        \"cell\": \"DownscalingCell\",\n",
    "        \"block\": \"IdentityBlock\",\n",
    "    },\n",
    "    \"ide_n\": {\n",
    "        \"cell\": \"NonscalingCell\",\n",
    "        \"block\": \"IdentityBlock\",\n",
    "    },\n",
    "    \"ide_u\": {\n",
    "        \"cell\": \"UpscalingCell\",\n",
    "        \"block\": \"IdentityBlock\",\n",
    "    },\n",
    "    \"res_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 3},\n",
    "    \"res_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 5},\n",
    "    \"res_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 7},\n",
    "    \"res_n_3\": {\"cell\": \"NonscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 3},\n",
    "    \"res_n_5\": {\"cell\": \"NonscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 5},\n",
    "    \"res_n_7\": {\"cell\": \"NonscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 7},\n",
    "    \"res_u_3\": {\"cell\": \"UpscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 3},\n",
    "    \"res_u_5\": {\"cell\": \"UpscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 5},\n",
    "    \"res_u_7\": {\"cell\": \"UpscalingCell\", \"block\": \"ResNetBlock\", \"kernel\": 7},\n",
    "    \"vgg_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 3},\n",
    "    \"vgg_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 5},\n",
    "    \"vgg_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 7},\n",
    "    \"vgg_n_3\": {\"cell\": \"NonscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 3},\n",
    "    \"vgg_n_5\": {\"cell\": \"NonscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 5},\n",
    "    \"vgg_n_7\": {\"cell\": \"NonscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 7},\n",
    "    \"vgg_u_3\": {\"cell\": \"UpscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 3},\n",
    "    \"vgg_u_5\": {\"cell\": \"UpscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 5},\n",
    "    \"vgg_u_7\": {\"cell\": \"UpscalingCell\", \"block\": \"VGGBlock\", \"kernel\": 7},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen_dice_coef_list = []\n",
    "num_splits = 5\n",
    "num_initializations = 5\n",
    "epochs = 30\n",
    "max_depth = 4\n",
    "stem_filters = 16\n",
    "evaluation_epochs = 10\n",
    "\n",
    "for initialization in range(num_initializations):\n",
    "\n",
    "    for fold in range(num_splits):\n",
    "        train_patients, val_patients = get_split_deterministic(\n",
    "            patients, fold=fold, num_splits=num_splits, random_state=initialization\n",
    "        )\n",
    "\n",
    "        train_dataset = ProstateDataset(train_patients, only_non_empty_slices=True)\n",
    "        val_dataset = ProstateDataset(val_patients, only_non_empty_slices=True)\n",
    "\n",
    "        train_dataloader = ProstateDataloader(\n",
    "            dataset=train_dataset, batch_size=batch_size, augmentation=train_augmentation\n",
    "        )\n",
    "        val_dataloader = ProstateDataloader(dataset=val_dataset, batch_size=batch_size, augmentation=val_augmentation)\n",
    "\n",
    "        model = build_net(\n",
    "            patch_size, stem_filters, max_depth, num_classes, fn_dict, net_list\n",
    "        )\n",
    "\n",
    "        # def learning_rate_fn(epoch):\n",
    "        #     initial_learning_rate = 1e-3\n",
    "        #     end_learning_rate = 1e-4\n",
    "        #     power = 0.9\n",
    "        #     return (\n",
    "        #         (initial_learning_rate - end_learning_rate)\n",
    "        #         * (1 - epoch / float(epochs)) ** (power)\n",
    "        #     ) + end_learning_rate\n",
    "\n",
    "        # lr_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "        #     learning_rate_fn, verbose=False\n",
    "        # )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_dataloader,\n",
    "            validation_data=val_dataloader,\n",
    "            epochs=epochs,\n",
    "            verbose=0,\n",
    "            #callbacks=[lr_callback],\n",
    "        )\n",
    "\n",
    "        print(history.history[\"val_gen_dice_coef\"][-evaluation_epochs:])\n",
    "\n",
    "        val_gen_dice_coef_list.extend(\n",
    "            history.history[\"val_gen_dice_coef\"][-evaluation_epochs:]\n",
    "        )\n",
    "\n",
    "        # for patient in val_patients:\n",
    "        #     patient_dataset = ProstateDataset([patient], only_non_empty_slices=True)\n",
    "        #     patient_dataloader = ProstateDataloader(patient_dataset, 1, val_augmentation, shuffle=False)\n",
    "        #     results = model.evaluate(patient_dataloader)\n",
    "        #     val_gen_dice_coef_patient = results[-1]\n",
    "        #     val_gen_dice_coef_list.append(val_gen_dice_coef_patient)\n",
    "\n",
    "        # plotting the dice coef results (accuracy) as a function of the number of epochs\n",
    "        plt.figure()\n",
    "        plt.plot(history.history[\"gen_dice_coef\"])\n",
    "        plt.plot(history.history[\"val_gen_dice_coef\"])\n",
    "        plt.title(\"DSC\")\n",
    "        plt.ylabel(\"DSC\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "\n",
    "        # plotting the dice coef results (loss function) as a function of the number of epochs\n",
    "        # plt.figure()\n",
    "        # plt.plot(history.history['loss'])\n",
    "        # plt.plot(history.history['val_loss'])\n",
    "        # plt.title('Model: Generalized Dice Coeficient')\n",
    "        # plt.ylabel('Dice Loss')\n",
    "        # plt.xlabel('Epoch')\n",
    "        # plt.legend(['Train', 'Test'], loc='upper right')\n",
    "        # plt.show()\n",
    "\n",
    "mean_val_gen_dice_coef = np.mean(val_gen_dice_coef_list)\n",
    "std_val_gen_dice_coef = np.std(val_gen_dice_coef_list)\n",
    "\n",
    "print(f\"Dice {mean_val_gen_dice_coef} +- {std_val_gen_dice_coef}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
