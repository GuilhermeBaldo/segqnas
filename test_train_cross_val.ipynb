{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from cnn import model\n",
    "\n",
    "from cnn.input import (\n",
    "    get_list_of_patients,\n",
    "    get_training_augmentation,\n",
    "    get_validation_augmentation,\n",
    "    Dataset,\n",
    "    Dataloader,\n",
    "    get_split_deterministic,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_params = {\n",
    "#     \"data_path\": \"spleen_dataset/data/Task09_Spleen_preprocessed\",\n",
    "#     \"num_classes\": 2,\n",
    "#     \"num_channels\": 1,\n",
    "#     \"skip_slices\": 0,\n",
    "#     \"image_size\": 128,\n",
    "#     \"batch_size\": 32,\n",
    "#     \"epochs\": 100,\n",
    "#     \"eval_epochs\": 20,\n",
    "#     \"folds\": 5,\n",
    "#     \"initializations\": 5,\n",
    "#     \"stem_filters\": 16,\n",
    "#     \"max_depth\": 4\n",
    "# }\n",
    "\n",
    "train_params = {\n",
    "    \"data_path\": \"prostate_dataset/data/Task05_Prostate_preprocessed\",\n",
    "    \"num_classes\": 3,\n",
    "    \"num_channels\": 2,\n",
    "    \"skip_slices\": 0,\n",
    "    \"image_size\": 128,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 100,\n",
    "    \"eval_epochs\": 20,\n",
    "    \"folds\": 5,\n",
    "    \"initializations\": 5,\n",
    "    \"stem_filters\": 16,\n",
    "    \"max_depth\": 4\n",
    "}\n",
    "\n",
    "unet_net_list = [\"vgg_n_3\",\"vgg_d_3\",\"vgg_d_3\",\"vgg_d_3\",\"vgg_d_3\",\"vgg_u_3\",\"vgg_u_3\",\"vgg_u_3\",\"vgg_u_3\",\"vgg_n_3\"]\n",
    "resunet_net_list = [\"res_n_3\",\"res_d_3\",\"res_d_3\",\"res_d_3\",\"res_d_3\",\"res_u_3\",\"res_u_3\",\"res_u_3\",\"res_u_3\",\"res_n_3\"]\n",
    "\n",
    "experiment_1_spleen_net_list = [\"vgg_n_3\",\"vgg_d_3\",\"vgg_u_3\",\"vgg_d_3\",\"vgg_d_3\",\"vgg_d_3\",\"vgg_d_3\",\"vgg_d_3\",\"vgg_n_3\",\"vgg_u_3\"]\n",
    "experiment_2_spleen_net_list = [\"den_n_3\",\"res_d_5\",\"vgg_d_5\",\"res_d_5\",\"inc_d_3\",\"res_u_3\",\"res_u_3\",\"res_u_5\",\"inc_u_3\",\"ide_n\"]\n",
    "experiment_3_spleen_net_list = [\"res_n_3\",\"den_d_3\",\"res_u_7\",\"inc_d_7\",\"vgg_d_3\",\"vgg_d_3\",\"res_d_5\",\"inc_d_7\",\"res_n_7\",\"den_u_3\"]\n",
    "experiment_4_spleen_net_list = [\"inc_n_3\",\"den_d_3\",\"den_d_3\",\"res_u_5\",\"res_n_3\",\"res_n_5\",\"res_d_5\",\"den_n_5\",\"den_n_5\",\"den_d_3\"]\n",
    "\n",
    "layer_dict = {\n",
    "    \"den_3\":   {                           \"block\": \"DenseBlock\",     \"kernel\": 3},\n",
    "    \"den_5\":   {                           \"block\": \"DenseBlock\",     \"kernel\": 5},\n",
    "    \"den_7\":   {                           \"block\": \"DenseBlock\",     \"kernel\": 7},\n",
    "    \"den_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\",     \"kernel\": 3},\n",
    "    \"den_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\",     \"kernel\": 5},\n",
    "    \"den_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"DenseBlock\",     \"kernel\": 7},\n",
    "    \"den_n_3\": {\"cell\": \"NonscalingCell\",  \"block\": \"DenseBlock\",     \"kernel\": 3},\n",
    "    \"den_n_5\": {\"cell\": \"NonscalingCell\",  \"block\": \"DenseBlock\",     \"kernel\": 5},\n",
    "    \"den_n_7\": {\"cell\": \"NonscalingCell\",  \"block\": \"DenseBlock\",     \"kernel\": 7},\n",
    "    \"den_u_3\": {\"cell\": \"UpscalingCell\",   \"block\": \"DenseBlock\",     \"kernel\": 3},\n",
    "    \"den_u_5\": {\"cell\": \"UpscalingCell\",   \"block\": \"DenseBlock\",     \"kernel\": 5},\n",
    "    \"den_u_7\": {\"cell\": \"UpscalingCell\",   \"block\": \"DenseBlock\",     \"kernel\": 7},\n",
    "    \"inc_3\":   {                           \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_5\":   {                           \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_7\":   {                           \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_n_3\": {\"cell\": \"NonscalingCell\",  \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_n_5\": {\"cell\": \"NonscalingCell\",  \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_n_7\": {\"cell\": \"NonscalingCell\",  \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"inc_u_3\": {\"cell\": \"UpscalingCell\",   \"block\": \"InceptionBlock\", \"kernel\": 3},\n",
    "    \"inc_u_5\": {\"cell\": \"UpscalingCell\",   \"block\": \"InceptionBlock\", \"kernel\": 5},\n",
    "    \"inc_u_7\": {\"cell\": \"UpscalingCell\",   \"block\": \"InceptionBlock\", \"kernel\": 7},\n",
    "    \"ide\":     {                           \"block\": \"IdentityBlock\"              },\n",
    "    \"ide_d\":   {\"cell\": \"DownscalingCell\", \"block\": \"IdentityBlock\"              },\n",
    "    \"ide_n\":   {\"cell\": \"NonscalingCell\",  \"block\": \"IdentityBlock\"              },\n",
    "    \"ide_u\":   {\"cell\": \"UpscalingCell\",   \"block\": \"IdentityBlock\"              },\n",
    "    \"res_3\":   {                           \"block\": \"ResNetBlock\",    \"kernel\": 3},\n",
    "    \"res_5\":   {                           \"block\": \"ResNetBlock\",    \"kernel\": 5},\n",
    "    \"res_7\":   {                           \"block\": \"ResNetBlock\",    \"kernel\": 7},\n",
    "    \"res_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\",    \"kernel\": 3},\n",
    "    \"res_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\",    \"kernel\": 5},\n",
    "    \"res_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"ResNetBlock\",    \"kernel\": 7},\n",
    "    \"res_n_3\": {\"cell\": \"NonscalingCell\",  \"block\": \"ResNetBlock\",    \"kernel\": 3},\n",
    "    \"res_n_5\": {\"cell\": \"NonscalingCell\",  \"block\": \"ResNetBlock\",    \"kernel\": 5},\n",
    "    \"res_n_7\": {\"cell\": \"NonscalingCell\",  \"block\": \"ResNetBlock\",    \"kernel\": 7},\n",
    "    \"res_u_3\": {\"cell\": \"UpscalingCell\",   \"block\": \"ResNetBlock\",    \"kernel\": 3},\n",
    "    \"res_u_5\": {\"cell\": \"UpscalingCell\",   \"block\": \"ResNetBlock\",    \"kernel\": 5},\n",
    "    \"res_u_7\": {\"cell\": \"UpscalingCell\",   \"block\": \"ResNetBlock\",    \"kernel\": 7},\n",
    "    \"vgg_3\":   {                           \"block\": \"VGGBlock\",       \"kernel\": 3},\n",
    "    \"vgg_5\":   {                           \"block\": \"VGGBlock\",       \"kernel\": 5},\n",
    "    \"vgg_7\":   {                           \"block\": \"VGGBlock\",       \"kernel\": 7},\n",
    "    \"vgg_d_3\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\",       \"kernel\": 3},\n",
    "    \"vgg_d_5\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\",       \"kernel\": 5},\n",
    "    \"vgg_d_7\": {\"cell\": \"DownscalingCell\", \"block\": \"VGGBlock\",       \"kernel\": 7},\n",
    "    \"vgg_n_3\": {\"cell\": \"NonscalingCell\",  \"block\": \"VGGBlock\",       \"kernel\": 3},\n",
    "    \"vgg_n_5\": {\"cell\": \"NonscalingCell\",  \"block\": \"VGGBlock\",       \"kernel\": 5},\n",
    "    \"vgg_n_7\": {\"cell\": \"NonscalingCell\",  \"block\": \"VGGBlock\",       \"kernel\": 7},\n",
    "    \"vgg_u_3\": {\"cell\": \"UpscalingCell\",   \"block\": \"VGGBlock\",       \"kernel\": 3},\n",
    "    \"vgg_u_5\": {\"cell\": \"UpscalingCell\",   \"block\": \"VGGBlock\",       \"kernel\": 5},\n",
    "    \"vgg_u_7\": {\"cell\": \"UpscalingCell\",   \"block\": \"VGGBlock\",       \"kernel\": 7},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_train(train_params, layer_dict, net_list, cell_list=None):\n",
    "\n",
    "    data_path = train_params[\"data_path\"]\n",
    "    num_classes = train_params[\"num_classes\"]\n",
    "    num_channels = train_params[\"num_channels\"]\n",
    "    skip_slices = train_params[\"skip_slices\"]\n",
    "    image_size = train_params[\"image_size\"]\n",
    "    batch_size = train_params[\"batch_size\"]\n",
    "    epochs = train_params[\"epochs\"]\n",
    "    eval_epochs = train_params[\"eval_epochs\"]\n",
    "    num_folds = train_params[\"folds\"]\n",
    "    num_initializations = train_params[\"initializations\"]\n",
    "    stem_filters = train_params[\"stem_filters\"]\n",
    "    max_depth = train_params[\"max_depth\"]\n",
    "\n",
    "    patch_size = (image_size, image_size, num_channels)\n",
    "\n",
    "    patients = get_list_of_patients(data_path)\n",
    "    train_augmentation =get_training_augmentation(patch_size)\n",
    "    val_augmentation = get_validation_augmentation(patch_size)\n",
    "\n",
    "    val_gen_dice_coef_list = []\n",
    "\n",
    "    for initialization in range(num_initializations):\n",
    "        for fold in range(num_folds):\n",
    "\n",
    "            net = model.build_net(\n",
    "                input_shape=patch_size,\n",
    "                num_classes=num_classes,\n",
    "                stem_filters=stem_filters,\n",
    "                max_depth=max_depth,\n",
    "                layer_dict=layer_dict,\n",
    "                net_list=net_list,\n",
    "                cell_list=cell_list,\n",
    "            )\n",
    "\n",
    "            train_patients, val_patients = get_split_deterministic(\n",
    "                patients,\n",
    "                fold=fold,\n",
    "                num_splits=num_folds,\n",
    "                random_state=initialization,\n",
    "            )\n",
    "\n",
    "            train_dataset = Dataset(\n",
    "                data_path=data_path,\n",
    "                patients=train_patients,\n",
    "                only_non_empty_slices=True,\n",
    "            )\n",
    "\n",
    "            val_dataset = Dataset(\n",
    "                data_path=data_path,\n",
    "                patients=val_patients,\n",
    "                only_non_empty_slices=True,\n",
    "            )\n",
    "\n",
    "            train_dataloader = Dataloader(\n",
    "                dataset=train_dataset,\n",
    "                batch_size=batch_size,\n",
    "                skip_slices=skip_slices,\n",
    "                augmentation=train_augmentation,\n",
    "                shuffle=True,\n",
    "            )\n",
    "\n",
    "            val_dataloader = Dataloader(\n",
    "                dataset=val_dataset,\n",
    "                batch_size=batch_size,\n",
    "                skip_slices=0,\n",
    "                augmentation=val_augmentation,\n",
    "                shuffle=False,\n",
    "            )\n",
    "            \n",
    "            def learning_rate_fn(epoch):\n",
    "                initial_learning_rate = 1e-3\n",
    "                end_learning_rate = 1e-4\n",
    "                power = 0.9\n",
    "                return (\n",
    "                    (initial_learning_rate - end_learning_rate)\n",
    "                    * (1 - epoch / float(epochs)) ** (power)\n",
    "                ) + end_learning_rate\n",
    "\n",
    "            lr_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "                learning_rate_fn, verbose=False\n",
    "            )\n",
    "\n",
    "            history = net.fit(\n",
    "                train_dataloader,\n",
    "                validation_data=val_dataloader,\n",
    "                epochs=epochs,\n",
    "                verbose=0,\n",
    "                callbacks=[lr_callback],\n",
    "            )\n",
    "\n",
    "            history_eval_epochs = history.history[\"val_gen_dice_coef\"][-eval_epochs:]\n",
    "\n",
    "            val_gen_dice_coef_list.extend(history_eval_epochs)\n",
    "\n",
    "            mean_dsc = np.mean(val_gen_dice_coef_list)\n",
    "            std_dsc = np.std(val_gen_dice_coef_list)\n",
    "            print(\n",
    "                f\"{fold + initialization*num_folds}/{num_folds*num_initializations}: {mean_dsc} +- {std_dsc}\"\n",
    "            )\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(history.history[\"gen_dice_coef\"])\n",
    "            plt.plot(history.history[\"val_gen_dice_coef\"])\n",
    "            plt.title(\"DSC\")\n",
    "            plt.ylabel(\"DSC\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "            plt.show()\n",
    "\n",
    "    mean_dsc = np.mean(val_gen_dice_coef_list)\n",
    "    std_dsc = np.std(val_gen_dice_coef_list)\n",
    "\n",
    "    return mean_dsc, std_dsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_train(train_params=train_params, layer_dict=layer_dict, net_list=unet_net_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_train(train_params=train_params, layer_dict=layer_dict, net_list=resunet_net_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_train(train_params=train_params, layer_dict=layer_dict, net_list=experiment_1_spleen_net_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_train(train_params=train_params, layer_dict=layer_dict, net_list=experiment_2_spleen_net_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_train(train_params=train_params, layer_dict=layer_dict, net_list=experiment_3_spleen_net_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_train(train_params=train_params, layer_dict=layer_dict, net_list=experiment_4_spleen_net_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('qnas')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8820744234b703bd445442e6ebc9db61d869d1d6be3e6a35ae5b30db245b9f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
